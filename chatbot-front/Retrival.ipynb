{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a3966-a3c1-4c24-a6f9-a64e8ecb8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of a Laravel opening in the provided context. The context only mentions an opportunity to work with Generative AI models, but it does not specify the technology or framework (such as Laravel) being used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client_groq = Groq(api_key=\"YOUR_GROQ_KEY\")\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a,b) / (np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def chat_with_rag(query):\n",
    "    # fetch docs from Laravel\n",
    "    docs = requests.get(\"http://127.0.0.1:8000/api/docs\").json()\n",
    "\n",
    "    qvec = embed_model.encode(query)\n",
    "\n",
    "    # compute cosine similarity in Python\n",
    "    scored = []\n",
    "    for d in docs:\n",
    "        emb = np.array(json.loads(d[\"embedding\"]))\n",
    "        score = cosine_sim(qvec, emb)\n",
    "        scored.append((score, d))\n",
    "\n",
    "    # top 3 results\n",
    "    top = sorted(scored, key=lambda x: x[0], reverse=True)[:3]\n",
    "\n",
    "    # build context\n",
    "    context = \"\\n\\n\".join(d[\"text\"] for _, d in top)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Use only the context below:\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
    "    ]\n",
    "\n",
    "    resp = client_groq.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=messages,\n",
    "        max_tokens=400,\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "    \n",
    "    \n",
    "\n",
    "print(chat_with_rag(\"Laravel opening available?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be246f0-9d52-473b-9557-8bdf0d65a4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
